{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "413d147094f640d1a571d06b59bcebc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0faaee19ec7e48809c40eeb7ac08bebd",
              "IPY_MODEL_2e285ade27c44bcc90c1402d79405a45",
              "IPY_MODEL_8a609d1b49414f1681e40a8973f26c8e"
            ],
            "layout": "IPY_MODEL_8dae8a5449d5403a845cec854b2877f6"
          }
        },
        "0faaee19ec7e48809c40eeb7ac08bebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1520205e14664dc69da836d4c54f641e",
            "placeholder": "​",
            "style": "IPY_MODEL_a68d705f4c3045db87f24a1667c89956",
            "value": "Epoch 19: 100%"
          }
        },
        "2e285ade27c44bcc90c1402d79405a45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9abbf4aee8d449a962cdcf2603c4073",
            "max": 130,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9bd59611558403f883c59c0873e86e0",
            "value": 130
          }
        },
        "8a609d1b49414f1681e40a8973f26c8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f39eda253d44432a60a4cffbbcec589",
            "placeholder": "​",
            "style": "IPY_MODEL_7119211943914d57ad81dab5f00ca6ab",
            "value": " 130/130 [00:22&lt;00:00,  5.69it/s, v_num=0]"
          }
        },
        "8dae8a5449d5403a845cec854b2877f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "1520205e14664dc69da836d4c54f641e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a68d705f4c3045db87f24a1667c89956": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9abbf4aee8d449a962cdcf2603c4073": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9bd59611558403f883c59c0873e86e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f39eda253d44432a60a4cffbbcec589": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7119211943914d57ad81dab5f00ca6ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f7684b86cc14a41923e075dcb87a1ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d96932fa06c742b890b8843a7428883e",
              "IPY_MODEL_4d87355c835045c7b13df08e64391d2d",
              "IPY_MODEL_287a2bad0de4416c9adef1e2f0c56697"
            ],
            "layout": "IPY_MODEL_3fdbc85942f047a29f51d775e0eaff2d"
          }
        },
        "d96932fa06c742b890b8843a7428883e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40cc4b9bd2374d74bbc8342ab36db810",
            "placeholder": "​",
            "style": "IPY_MODEL_8731845dd0c44eaa8fdf58174fe1cfe8",
            "value": "Testing DataLoader 0: 100%"
          }
        },
        "4d87355c835045c7b13df08e64391d2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03678acc1fcb4c638c83a86544cd90a2",
            "max": 39,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d7d9b1eddc6741f29bff848f668dd244",
            "value": 39
          }
        },
        "287a2bad0de4416c9adef1e2f0c56697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d473422a2776405d9e61049e2399029b",
            "placeholder": "​",
            "style": "IPY_MODEL_e494ea88fb044ab4a62abd7b91ac450f",
            "value": " 39/39 [00:04&lt;00:00,  9.01it/s]"
          }
        },
        "3fdbc85942f047a29f51d775e0eaff2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "40cc4b9bd2374d74bbc8342ab36db810": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8731845dd0c44eaa8fdf58174fe1cfe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03678acc1fcb4c638c83a86544cd90a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7d9b1eddc6741f29bff848f668dd244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d473422a2776405d9e61049e2399029b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e494ea88fb044ab4a62abd7b91ac450f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CUknot/NLP/blob/main/Lab2_2_neural_language_modeling_to_student_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "15QfB7RAuXAc"
      },
      "source": [
        "# Neural Language Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gucid6KNuXAe"
      },
      "source": [
        "In this Exercise, we will be using Pytorch Lightning to implement our neural LM. Your job will be just to write the forward method of the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## setup"
      ],
      "metadata": {
        "id": "yL_M2zf4myYa"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRRrn78ZjL54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5ce4b9f-4790-4689-a2d4-1ca38d627987"
      },
      "source": [
        "# #download corpus\n",
        "!wget --no-check-certificate https://github.com/ekapolc/nlp_2019/raw/master/HW4/BEST2010.zip\n",
        "!unzip BEST2010.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-18 08:43:50--  https://github.com/ekapolc/nlp_2019/raw/master/HW4/BEST2010.zip\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW4/BEST2010.zip [following]\n",
            "--2025-01-18 08:43:51--  https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW4/BEST2010.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7423530 (7.1M) [application/zip]\n",
            "Saving to: ‘BEST2010.zip’\n",
            "\n",
            "BEST2010.zip        100%[===================>]   7.08M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2025-01-18 08:43:52 (90.9 MB/s) - ‘BEST2010.zip’ saved [7423530/7423530]\n",
            "\n",
            "Archive:  BEST2010.zip\n",
            "   creating: BEST2010/\n",
            "  inflating: BEST2010/article.txt    \n",
            "  inflating: BEST2010/encyclopedia.txt  \n",
            "  inflating: BEST2010/news.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightning"
      ],
      "metadata": {
        "id": "SGmYebp38OUl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cd9c7fc-b8c2-40aa-d1d5-f845828c936b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightning\n",
            "  Downloading lightning-2.5.0.post0-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/40.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.11/dist-packages (from lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2024.10.0)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning)\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (24.2)\n",
            "Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (2.5.1+cu121)\n",
            "Collecting torchmetrics<3.0,>=0.7.0 (from lightning)\n",
            "  Downloading torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (4.12.2)\n",
            "Collecting pytorch-lightning (from lightning)\n",
            "  Downloading pytorch_lightning-2.5.0.post0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.11.11)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (75.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<4.0,>=2.1.0->lightning) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<4.0,>=2.1.0->lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics<3.0,>=0.7.0->lightning) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (3.10)\n",
            "Downloading lightning-2.5.0.post0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Downloading torchmetrics-1.6.1-py3-none-any.whl (927 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m927.3/927.3 kB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.0.post0-py3-none-any.whl (819 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.3/819.3 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch-lightning, lightning\n",
            "Successfully installed lightning-2.5.0.post0 lightning-utilities-0.11.9 pytorch-lightning-2.5.0.post0 torchmetrics-1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## code"
      ],
      "metadata": {
        "id": "IR4HK5jQm17K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_word_count = 0\n",
        "best2010 = []\n",
        "with open('BEST2010/news.txt','r',encoding='utf-8') as f:\n",
        "  for i,line in enumerate(f):\n",
        "    line=line.strip()[:-1] #remove the trailing |\n",
        "    total_word_count += len(line.split(\"|\"))\n",
        "    best2010.append(line)\n",
        "\n",
        "train = best2010[:int(len(best2010)*0.7)]\n",
        "test = best2010[int(len(best2010)*0.7):]\n",
        "#Training data\n",
        "train_word_count =0\n",
        "for line in train:\n",
        "    for word in line.split('|'):\n",
        "        train_word_count+=1\n",
        "print ('Total sentences in BEST2010 news training dataset :\\t'+ str(len(train)))\n",
        "print ('Total word counts in BEST2010 news training dataset :\\t'+ str(train_word_count))"
      ],
      "metadata": {
        "id": "oPE1RqKOrWJ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cca2bc32-c5a2-4145-a120-684c7331f981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sentences in BEST2010 news training dataset :\t21678\n",
            "Total word counts in BEST2010 news training dataset :\t1042797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are going to use a library from huggingface called `tokenizers`. This will help us create a vocabulary and handle the encoding and decoding, i.e., convert text to its corresponding ID (which will be learned by the tokenizer)."
      ],
      "metadata": {
        "id": "SQBjqe5arHGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.pre_tokenizers import CharDelimiterSplit\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "\n",
        "#Basically, we just use the new tokenizer as our vocab building tool.\n",
        "#In practice, you will have to use a compatible tokenizer like newmm to tokenize the corpus first then do this step\n",
        "tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
        "tokenizer.pre_tokenizer = CharDelimiterSplit(delimiter=\"|\") #now the tokenizer will split \"|\" for us\n",
        "trainer = WordLevelTrainer(min_frequency=3,  #we can set a frequency threshold for taking a word into our vocab. for this example, words with freq < 3 will be excluded from the vocab.\n",
        "                           special_tokens=[\"[UNK]\", \"<s>\", \"</s>\"]) #these are our special tokens: for unknown, begin-of-sentence, and end-of-sentence, respectively.\n",
        "tokenizer.train_from_iterator(train, trainer=trainer)"
      ],
      "metadata": {
        "id": "elwE0gh2rE3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.get_vocab()) #same as nltk"
      ],
      "metadata": {
        "id": "TrKtjv4PJpg2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7075ff62-f007-44fc-8ca5-71bee226d593"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9062"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(\"กฎหมาย|กับ|การ|เบียดบัง|คน|จน|asdf\").tokens #tokens we get after tokenizing this sentence. unknown words will be tokenized as [UNK]"
      ],
      "metadata": {
        "id": "WqM_jrZwrJpB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bba982fc-a9bc-478e-8ba3-9339d7851827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['กฎหมาย', 'กับ', 'การ', 'เบียดบัง', 'คน', 'จน', '[UNK]']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(\"กฎหมาย|กับ|การ|เบียดบัง|คน|จน|asdf\").ids #this is what we will feed to the LM"
      ],
      "metadata": {
        "id": "1r1pJ1B_sp9j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3ee3b87-1215-473b-80c3-4a54f7e9eea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[242, 28, 5, 8883, 22, 190, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import lightning as L\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "Fkx6CSoXWXmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L.seed_everything(42, workers=True)"
      ],
      "metadata": {
        "id": "3XHJsP8_898x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f876a11e-800c-4049-a237-d8a0bc1e7fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Seed set to 42\n",
            "INFO:lightning.fabric.utilities.seed:Seed set to 42\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset(Dataset):\n",
        "  def __init__(self, data, seq_len = 128):\n",
        "    #  data is currently a list of sentences\n",
        "    #  [sent1,\n",
        "    #   sent2,\n",
        "    #   ...,\n",
        "    #  ]\n",
        "\n",
        "    data = [d+'|</s>' for d in data] #append an </s> token to each sentence\n",
        "    encodings = tokenizer.encode_batch(data) #encode (turn token into token_id) data\n",
        "    token_ids = [enc.ids for enc in encodings] #get the token ids for each sentence\n",
        "    flatten_token_ids = list(itertools.chain(*token_ids)) #turn a list of token_ids into one long token_ids\n",
        "    ## now data looks like this [sent1_ids </s> sent2_ids </s> ...]\n",
        "    encoded = torch.LongTensor(flatten_token_ids)\n",
        "\n",
        "    #remove some left over tokens so that we can form batches of seq_len (128 in this case). Optionally, we can use padding tokens instead.\n",
        "    left_over = len(encoded) % seq_len\n",
        "    encoded = encoded[:len(encoded)-left_over]\n",
        "    self.encoded = encoded.view(-1, seq_len) #reshape data so it becomes a 2-D matrix of shape (len(encoded)//128, 128), i.e. each row contains data of len==128\n",
        "    ## now data looks like this\n",
        "    ## [ [1,2,3, ... , 128] (this is just an example, not actual input_ids)\n",
        "    ##   [1,2,3, ... , 128]\n",
        "    ##   [1,2,3, ... , 128]\n",
        "    ## ]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.encoded[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.encoded)"
      ],
      "metadata": {
        "id": "-r_kyrrrDHZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_batch_size = 64\n",
        "test_batch_size = 128\n",
        "train_dataset = TextDataset(train)\n",
        "train_loader = DataLoader(train_dataset, batch_size = train_batch_size, shuffle = True) #DataLoader will take care of the random sampling and batching of data\n",
        "\n",
        "test_dataset = TextDataset(test)\n",
        "test_loader = DataLoader(test_dataset, batch_size = test_batch_size, shuffle = False)"
      ],
      "metadata": {
        "id": "YmW-K0XBZ4Dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model : Implement the forward function here\n",
        "\n",
        "> เพิ่มข้อความทั้งย่อหน้าที่ยกมา\n",
        "\n"
      ],
      "metadata": {
        "id": "ElhZcB94MUtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(L.LightningModule):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, dropout_rate, learning_rate, criterion):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim) #this will turn the token ids into vectors\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers,\n",
        "                    dropout=dropout_rate, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size) #turn the vectors back into token ids\n",
        "        self.learning_rate = learning_rate\n",
        "        self.criterion = criterion\n",
        "\n",
        "    def forward(self, src):\n",
        "        embeddings = self.embedding(src)  # Shape: [batch_size, seq_len, embedding_dim]\n",
        "\n",
        "        # Pass embeddings through the LSTM\n",
        "        lstm_out, _ = self.lstm(embeddings)  # lstm_out: [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        # Apply dropout\n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "\n",
        "        # Project the hidden states to vocab size\n",
        "        output = self.fc(lstm_out)  # Shape: [batch_size, seq_len, vocab_size]\n",
        "\n",
        "        return output\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "\n",
        "        src = batch[:, :-1]\n",
        "        target = batch[:, 1:]\n",
        "        prediction = self(src) # run the sequence through the model (the forward method)\n",
        "        prediction = prediction.reshape(-1, vocab_size)\n",
        "        target = target.reshape(-1)\n",
        "        loss = self.criterion(prediction, target)\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "\n",
        "        src = batch[:, :-1]  #[batch_size (64) , seq_len-1 (127)] except last words\n",
        "        target = batch[:, 1:] #[batch_size (64) , seq_len-1 (127)] except first words\n",
        "        with torch.no_grad(): #disable gradient calculation for faster inference\n",
        "          prediction = self(src) #[batch_size (64), seq_len-1 (127) , vocab size (9000)]\n",
        "        prediction = prediction.reshape(-1, vocab_size) #[batch_size*(seq_len-1) (64*127=8128) , vocab]\n",
        "        target = target.reshape(-1) #[batch_size (64), seq_len-1 (127)] -> [batch_size*(seq_len-1) (8128)]\n",
        "        loss = self.criterion(prediction, target)\n",
        "        self.log(\"test_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return optim.Adam(self.parameters(), lr=self.learning_rate)"
      ],
      "metadata": {
        "id": "nKNJAolug-1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = tokenizer.get_vocab_size()\n",
        "embedding_dim = 200\n",
        "hidden_dim = 512\n",
        "num_layers = 3\n",
        "dropout_rate = 0.2\n",
        "lr = 1e-3"
      ],
      "metadata": {
        "id": "jBnYCh-miOEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "model = LSTM(vocab_size, embedding_dim, hidden_dim, num_layers, dropout_rate, lr, criterion)"
      ],
      "metadata": {
        "id": "HHWXaPsvigPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lightning.pytorch.loggers import CSVLogger\n",
        "csv_logger = CSVLogger(\"log\")"
      ],
      "metadata": {
        "id": "_yNEZ4jwXumR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "eZwqhWicMdH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = L.Trainer(\n",
        "    max_epochs=20,\n",
        "    logger=csv_logger,\n",
        "    deterministic=True\n",
        ")"
      ],
      "metadata": {
        "id": "kr0zdeMAjD1U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5006bdbd-fa3f-42d4-b9ed-2039e18b52c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(model, train_dataloaders=train_loader) # takes about 8 mins"
      ],
      "metadata": {
        "id": "A9qcwNA0mN6J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639,
          "referenced_widgets": [
            "413d147094f640d1a571d06b59bcebc6",
            "0faaee19ec7e48809c40eeb7ac08bebd",
            "2e285ade27c44bcc90c1402d79405a45",
            "8a609d1b49414f1681e40a8973f26c8e",
            "8dae8a5449d5403a845cec854b2877f6",
            "1520205e14664dc69da836d4c54f641e",
            "a68d705f4c3045db87f24a1667c89956",
            "d9abbf4aee8d449a962cdcf2603c4073",
            "e9bd59611558403f883c59c0873e86e0",
            "2f39eda253d44432a60a4cffbbcec589",
            "7119211943914d57ad81dab5f00ca6ab"
          ]
        },
        "outputId": "d86e6eeb-a846-431f-8082-1c388cc396bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name      | Type             | Params | Mode \n",
            "-------------------------------------------------------\n",
            "0 | embedding | Embedding        | 1.8 M  | train\n",
            "1 | lstm      | LSTM             | 5.7 M  | train\n",
            "2 | dropout   | Dropout          | 0      | train\n",
            "3 | fc        | Linear           | 4.6 M  | train\n",
            "4 | criterion | CrossEntropyLoss | 0      | train\n",
            "-------------------------------------------------------\n",
            "12.1 M    Trainable params\n",
            "0         Non-trainable params\n",
            "12.1 M    Total params\n",
            "48.504    Total estimated model params size (MB)\n",
            "5         Modules in train mode\n",
            "0         Modules in eval mode\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name      | Type             | Params | Mode \n",
            "-------------------------------------------------------\n",
            "0 | embedding | Embedding        | 1.8 M  | train\n",
            "1 | lstm      | LSTM             | 5.7 M  | train\n",
            "2 | dropout   | Dropout          | 0      | train\n",
            "3 | fc        | Linear           | 4.6 M  | train\n",
            "4 | criterion | CrossEntropyLoss | 0      | train\n",
            "-------------------------------------------------------\n",
            "12.1 M    Trainable params\n",
            "0         Non-trainable params\n",
            "12.1 M    Total params\n",
            "48.504    Total estimated model params size (MB)\n",
            "5         Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "413d147094f640d1a571d06b59bcebc6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: `Trainer.fit` stopped: `max_epochs=20` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=20` reached.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing"
      ],
      "metadata": {
        "id": "uUfWF_V6Me9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_result = trainer.test(model, dataloaders=test_loader)"
      ],
      "metadata": {
        "id": "WXVj9ewNqweZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "9f7684b86cc14a41923e075dcb87a1ce",
            "d96932fa06c742b890b8843a7428883e",
            "4d87355c835045c7b13df08e64391d2d",
            "287a2bad0de4416c9adef1e2f0c56697",
            "3fdbc85942f047a29f51d775e0eaff2d",
            "40cc4b9bd2374d74bbc8342ab36db810",
            "8731845dd0c44eaa8fdf58174fe1cfe8",
            "03678acc1fcb4c638c83a86544cd90a2",
            "d7d9b1eddc6741f29bff848f668dd244",
            "d473422a2776405d9e61049e2399029b",
            "e494ea88fb044ab4a62abd7b91ac450f"
          ]
        },
        "outputId": "fdd9d8f0-0f6e-4ceb-e83d-2a31e2a0b5ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Testing: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f7684b86cc14a41923e075dcb87a1ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    4.164413928985596    \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     4.164413928985596     </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "4pVjEyYDtnc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Perplexity : {np.exp(test_result[0]['test_loss'])}\")"
      ],
      "metadata": {
        "id": "uuIPToGQs-ZG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c19e460-db8f-4537-cfe1-97a04475227d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity : 64.35495481535708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval() #disable dropout"
      ],
      "metadata": {
        "id": "pAZwiRqsnOPe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2215caa0-cecd-4be5-d86f-3d7f6e932237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM(\n",
              "  (embedding): Embedding(9062, 200)\n",
              "  (lstm): LSTM(200, 512, num_layers=3, batch_first=True, dropout=0.2)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (fc): Linear(in_features=512, out_features=9062, bias=True)\n",
              "  (criterion): CrossEntropyLoss()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unk_token_id = tokenizer.encode(\"[UNK]\").ids\n",
        "eos_token_id = tokenizer.encode(\"</s>\").ids"
      ],
      "metadata": {
        "id": "VFtebDAmVh_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_seq(context, max_new_token = 10):\n",
        "  encoded = tokenizer.encode(context).ids\n",
        "  with torch.no_grad():\n",
        "      for i in range(max_new_token):\n",
        "          src = torch.LongTensor([encoded]).to(model.device)\n",
        "          prediction = model(src)\n",
        "          probs = torch.softmax(prediction[:, -1] / 1, dim=-1)\n",
        "          prediction = torch.multinomial(probs, num_samples=1).item()\n",
        "\n",
        "          while prediction == unk_token_id:\n",
        "              prediction = torch.multinomial(probs, num_samples=1).item()\n",
        "\n",
        "          if prediction == eos_token_id:\n",
        "              break\n",
        "\n",
        "          encoded.append(prediction)\n",
        "\n",
        "  return tokenizer.decode(encoded)"
      ],
      "metadata": {
        "id": "hj-V4OsDqpBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"<s>|วัน|จันทร์\"\n",
        "generate_seq(context, 50)"
      ],
      "metadata": {
        "id": "u20r9w8zvJi4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "ca671cf7-e09d-4a2c-f73e-583fd62d166d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'วัน จันทร์ ที่   26   มิถุนายน     ปลัด   แจก ประชาสัมพันธ์ ผู้ว่า   นายก เทศมนตรี กรุงเทพมหานคร   ตชด.   รมต.   ร่วม กัน ได้ รับ ผล กระทบ ใน วัน พรุ่ง ที่   1   มิถุนายน   ที่ ผ่าน มา   ต่อ เข้า ประชุม ด้วย โดย  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"<s>|นายก\"\n",
        "generate_seq(context, 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "573PUVd6oDZC",
        "outputId": "136e4565-c372-4039-810b-2e067f8ba148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'นายก ฯ   หรือ ต่อ คน   มี   กกต.   เพราะ เป็น เรื่อง ประกอบ ว่า   ใคร   ถึง เวลา ไหน มาก กว่า   ยัง เงียบหาย หรือ เทียบเท่า กัน   โดย สำนึก ความ ไม่ กล้า ใน ที่สุด   หรือ ทุก ชุด ที่ ดี อยู่แล้ว   ฐาน ทำลาย จริยธรรม ทั้งหมด  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Questions: Answer the following in MyCourseville\n",
        "\n",
        "1. What is the perplexity of the neural LM you trained?\n",
        "2. Paste your favorite sentence generated with the LM.\n",
        "- นายก ฯ   หรือ ต่อ คน   มี   กกต.   เพราะ เป็น เรื่อง ประกอบ ว่า   ใคร   ถึง เวลา ไหน มาก กว่า   ยัง เงียบหาย หรือ เทียบเท่า กัน   โดย สำนึก ความ ไม่ กล้า ใน ที่สุด   หรือ ทุก ชุด ที่ ดี อยู่แล้ว   ฐาน ทำลาย จริยธรรม ทั้งหมด"
      ],
      "metadata": {
        "id": "1fr536NVvGX3"
      }
    }
  ]
}