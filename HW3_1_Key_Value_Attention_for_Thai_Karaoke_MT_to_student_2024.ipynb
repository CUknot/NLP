{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9b2d779ecd4e49339e397af4e366e302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8b78bdad2af43479507336383f5b1fc",
              "IPY_MODEL_919d38c9694e4e5dba41ffdfefe2f5c5",
              "IPY_MODEL_df2ee00b533046f08a2db2051eaa6159"
            ],
            "layout": "IPY_MODEL_0f95b4a99eca48c0a2693f8a3b6186b6"
          }
        },
        "f8b78bdad2af43479507336383f5b1fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_555043b0f2e84381a34f4dff0f5c379e",
            "placeholder": "​",
            "style": "IPY_MODEL_c58683ab7d124f3ebaf5cb38046c666e",
            "value": "Epoch 99: 100%"
          }
        },
        "919d38c9694e4e5dba41ffdfefe2f5c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3002562040044b986f5c9608fcd0c9b",
            "max": 341,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f6feb614ebc2427fb6bb815153f49ea8",
            "value": 341
          }
        },
        "df2ee00b533046f08a2db2051eaa6159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_387f274446264bcf8fc4b64c6b003d49",
            "placeholder": "​",
            "style": "IPY_MODEL_e533664c11bb43b7b413e1f303bcb3ef",
            "value": " 341/341 [00:12&lt;00:00, 27.78it/s, v_num=e0lf]"
          }
        },
        "0f95b4a99eca48c0a2693f8a3b6186b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "555043b0f2e84381a34f4dff0f5c379e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c58683ab7d124f3ebaf5cb38046c666e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3002562040044b986f5c9608fcd0c9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6feb614ebc2427fb6bb815153f49ea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "387f274446264bcf8fc4b64c6b003d49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e533664c11bb43b7b413e1f303bcb3ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d99f005e0db64121bd272347b193ecf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52c7190f07414fe580c691ccc3231f13",
              "IPY_MODEL_82116e868c724debb84e0de00383482a",
              "IPY_MODEL_05ac5405cc7f41e0a80fcae062ff7b4c"
            ],
            "layout": "IPY_MODEL_cadeb7b11c38405c99b1cb9e4cfa3a93"
          }
        },
        "52c7190f07414fe580c691ccc3231f13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c3e1443c1f246f993f9acbc15ac471b",
            "placeholder": "​",
            "style": "IPY_MODEL_fd083703da314098a130d6562dbdfaff",
            "value": "Predicting DataLoader 0: 100%"
          }
        },
        "82116e868c724debb84e0de00383482a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4db1533616214c148597a944c22d6a68",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01aac22f0e934d4a9be960f0dfcb63cf",
            "value": 8
          }
        },
        "05ac5405cc7f41e0a80fcae062ff7b4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b6109a3ed5b416cb431a4d41cf590b0",
            "placeholder": "​",
            "style": "IPY_MODEL_e28a14ab1d254150951ab0a047a949b3",
            "value": " 8/8 [00:00&lt;00:00, 59.99it/s]"
          }
        },
        "cadeb7b11c38405c99b1cb9e4cfa3a93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "9c3e1443c1f246f993f9acbc15ac471b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd083703da314098a130d6562dbdfaff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4db1533616214c148597a944c22d6a68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01aac22f0e934d4a9be960f0dfcb63cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b6109a3ed5b416cb431a4d41cf590b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e28a14ab1d254150951ab0a047a949b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CUknot/NLP/blob/main/HW3_1_Key_Value_Attention_for_Thai_Karaoke_MT_to_student_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfUmXr1D1ZSR"
      },
      "source": [
        "# Key-Value Attention for Thai Karaoke Character-level Machine Translation (Many-to-Many, encoder-decoder)\n",
        "\n",
        "In this homework, you will create an MT model with attention mechnism that coverts names of Thai 2019 MP candidates from Thai script to Roman(Latin) script. E.g. นิยม-->niyom\n",
        "\n",
        "The use of Pytorch Lightning is optional but recommended. You can use Pytorch if you prefer."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightning wandb\n",
        "!wget https://github.com/Phonbopit/sarabun-webfont/raw/master/fonts/thsarabunnew-webfont.ttf"
      ],
      "metadata": {
        "id": "18KMSkqZ-Pt-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d964981-04b3-4cb9-9035-f1dd8a9f4282"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightning\n",
            "  Downloading lightning-2.5.0.post0-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/40.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.4)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.11/dist-packages (from lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2024.10.0)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning)\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (24.2)\n",
            "Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (2.5.1+cu121)\n",
            "Collecting torchmetrics<3.0,>=0.7.0 (from lightning)\n",
            "  Downloading torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (4.12.2)\n",
            "Collecting pytorch-lightning (from lightning)\n",
            "  Downloading pytorch_lightning-2.5.0.post0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.10.5)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.20.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.11.11)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<4.0,>=2.1.0->lightning) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<4.0,>=2.1.0->lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics<3.0,>=0.7.0->lightning) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.18.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (3.0.2)\n",
            "Downloading lightning-2.5.0.post0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Downloading torchmetrics-1.6.1-py3-none-any.whl (927 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m927.3/927.3 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.0.post0-py3-none-any.whl (819 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.3/819.3 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch-lightning, lightning\n",
            "Successfully installed lightning-2.5.0.post0 lightning-utilities-0.11.9 pytorch-lightning-2.5.0.post0 torchmetrics-1.6.1\n",
            "--2025-01-25 14:38:34--  https://github.com/Phonbopit/sarabun-webfont/raw/master/fonts/thsarabunnew-webfont.ttf\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Phonbopit/sarabun-webfont/master/fonts/thsarabunnew-webfont.ttf [following]\n",
            "--2025-01-25 14:38:35--  https://raw.githubusercontent.com/Phonbopit/sarabun-webfont/master/fonts/thsarabunnew-webfont.ttf\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 98308 (96K) [application/octet-stream]\n",
            "Saving to: ‘thsarabunnew-webfont.ttf’\n",
            "\n",
            "thsarabunnew-webfon 100%[===================>]  96.00K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-01-25 14:38:35 (5.04 MB/s) - ‘thsarabunnew-webfont.ttf’ saved [98308/98308]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKCBCWKARZEx",
        "outputId": "8b8cd784-4286-41d1-e2f3-82c766517bdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka2TN8IV1ZSU"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "mpl.font_manager.fontManager.addfont('thsarabunnew-webfont.ttf') # 3.2+\n",
        "mpl.rc('font', family='TH Sarabun New')\n",
        "import torch\n",
        "# import torchtext\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import lightning as L\n",
        "import numpy as np\n",
        "\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-f_s6vX1ZSZ"
      },
      "source": [
        "## Load Dataset\n",
        "We have generated a toy dataset using names of Thai MP candidates in 2019 Thai General Election from elect.in.th's github(https://github.com/codeforthailand/dataset-election-62-candidates) and tltk (https://pypi.org/project/tltk/) library to convert them into Roman script.\n",
        "\n",
        "```\n",
        "ไกรสีห์ kraisi\n",
        "พัชรี phatri\n",
        "ธีระ thira\n",
        "วุฒิกร wutthikon\n",
        "ไสว sawai\n",
        "สัมภาษณ์  samphat\n",
        "วศิน wasin\n",
        "ทินวัฒน์ thinwat\n",
        "ศักดินัย sakdinai\n",
        "สุรศักดิ์ surasak\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/mp_name_th_en.csv"
      ],
      "metadata": {
        "id": "Jte-Csrf-4kd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fcc6b3e-41af-4530-cdc3-225182cbab7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-25 14:39:18--  https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/mp_name_th_en.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 324399 (317K) [text/plain]\n",
            "Saving to: ‘mp_name_th_en.csv’\n",
            "\n",
            "\rmp_name_th_en.csv     0%[                    ]       0  --.-KB/s               \rmp_name_th_en.csv   100%[===================>] 316.80K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-01-25 14:39:18 (8.96 MB/s) - ‘mp_name_th_en.csv’ saved [324399/324399]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9zXp7KH1ZSa"
      },
      "source": [
        "import csv\n",
        "\n",
        "with open('mp_name_th_en.csv') as csvfile:\n",
        "    readCSV = csv.reader(csvfile, delimiter=',')\n",
        "    name_th = []\n",
        "    name_en = []\n",
        "    for row in readCSV:\n",
        "        temp_th = row[0]\n",
        "        temp_en = row[1]\n",
        "\n",
        "        name_th.append(temp_th)\n",
        "        name_en.append(temp_en)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCsqrXxu1ZSe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2f58f5d-d0bd-46de-bf55-0b0ee409eed5"
      },
      "source": [
        "for th, en in zip(name_th[:10],name_en[:10]):\n",
        "    print(th,en)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ไกรสีห์ kraisi\n",
            "พัชรี phatri\n",
            "ธีระ thira\n",
            "วุฒิกร wutthikon\n",
            "ไสว sawai\n",
            "สัมภาษณ์  samphat\n",
            "วศิน wasin\n",
            "ทินวัฒน์ thinwat\n",
            "ศักดินัย sakdinai\n",
            "สุรศักดิ์ surasak\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvW8xqT81ZSh"
      },
      "source": [
        "## TODO1: Preprocess dataset\n",
        "* You will need 2 vocabularies (1 for input and another for output)\n",
        "* DON'T FORGET TO INCLUDE special token for padding (for both input and output)\n",
        "* DON'T FORGET TO INCLUDE special token for the end of word symbol (output)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rv1Xd9A1ZSi",
        "outputId": "e44cc22e-435d-45ba-ad20-dfd8813b76f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Preprocessing\n",
        "input_chars = list(set(''.join(name_th)))\n",
        "output_chars = list(set(''.join(name_en)))\n",
        "data_size, vocab_size = len(name_th), len(input_chars)+1\n",
        "output_vocab_size = len(output_chars)+2#+2 for special end of sentence token/PADDING\n",
        "print('There are %d lines and %d unique characters in your input data.' % (data_size, vocab_size))\n",
        "maxlen = len( max(name_th, key=len)) #max input length\n",
        "maxlen_out = len( max(name_en, key=len)) #max input length"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 10887 lines and 65 unique characters in your input data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo381I_t1ZSm",
        "outputId": "37a43212-6eff-4270-b08a-e1ebf8475702",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Max input length:\", maxlen)\n",
        "print(\"Max output length:\", maxlen_out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max input length: 20\n",
            "Max output length: 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(characters, special_tokens):\n",
        "    \"\"\"\n",
        "    Builds a vocabulary from a set of characters and special tokens.\n",
        "    Args:\n",
        "        characters: A set or list of characters to include in the vocabulary.\n",
        "        special_tokens: A list of special tokens to prepend to the vocabulary.\n",
        "\n",
        "    Returns:\n",
        "        vocab: A dictionary mapping each character/token to an index.\n",
        "        reverse_vocab: A dictionary mapping each index back to its character/token.\n",
        "    \"\"\"\n",
        "    vocab = {token: idx for idx, token in enumerate(special_tokens)}\n",
        "    for char in characters:\n",
        "        if char not in vocab:\n",
        "            vocab[char] = len(vocab)\n",
        "    reverse_vocab = {idx: char for char, idx in vocab.items()}\n",
        "    return vocab, reverse_vocab\n",
        "\n",
        "# Example Thai and English characters\n",
        "thai_characters = set(\"\".join(name_th))  # Characters from Thai names\n",
        "english_characters = set(\"\".join(name_en))  # Characters from English names\n",
        "\n",
        "# Define special tokens\n",
        "special_tokens = [\"<pad>\", \"<eow>\"]\n",
        "\n",
        "# Build vocabularies\n",
        "thai_vocab, thai_reverse_vocab = build_vocab(thai_characters, special_tokens)\n",
        "english_vocab, english_reverse_vocab = build_vocab(english_characters, special_tokens)"
      ],
      "metadata": {
        "id": "gh2VF6XWt1EO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"thai_vocab: {thai_vocab}\")\n",
        "print(f\"english_vocab: {english_vocab}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPADhX7Ct2e9",
        "outputId": "f5518950-7ed5-412a-9a2a-119ba8b031e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "thai_vocab: {'<pad>': 0, '<eow>': 1, 'ั': 2, 'ิ': 3, 'โ': 4, '๊': 5, 'ฌ': 6, 'ุ': 7, 'ภ': 8, 'จ': 9, 'ป': 10, '้': 11, 'ื': 12, 'ส': 13, 'ฑ': 14, 'ก': 15, 'า': 16, 'ด': 17, 'ฏ': 18, '็': 19, 'ธ': 20, 'ไ': 21, 'พ': 22, 'ใ': 23, 'ท': 24, 'ฎ': 25, 'ห': 26, 'ศ': 27, 'ซ': 28, 'ง': 29, '่': 30, 'แ': 31, 'ต': 32, 'ณ': 33, 'ู': 34, 'บ': 35, 'ค': 36, 'ฮ': 37, 'ฬ': 38, 'ฝ': 39, 'ษ': 40, 'ญ': 41, 'ข': 42, 'ม': 43, 'ึ': 44, 'ฆ': 45, '๋': 46, 'ี': 47, 'ฟ': 48, 'ล': 49, 'ถ': 50, 'ผ': 51, ' ': 52, 'เ': 53, 'ฒ': 54, '์': 55, 'อ': 56, 'ำ': 57, 'ฐ': 58, 'น': 59, 'ฉ': 60, 'ะ': 61, 'ว': 62, 'ช': 63, 'ย': 64, 'ร': 65}\n",
            "english_vocab: {'<pad>': 0, '<eow>': 1, 'l': 2, 'y': 3, 'i': 4, '-': 5, 's': 6, 'w': 7, 'o': 8, 'e': 9, 'c': 10, 'k': 11, 'd': 12, 'r': 13, 'n': 14, 'a': 15, 'p': 16, 'u': 17, 'h': 18, 'f': 19, 't': 20, 'm': 21, 'b': 22, 'g': 23}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_encode = lambda s: [thai_vocab[c] for c in s] # encoder: take a string, output a list of integers\n",
        "input_decode = lambda l: ''.join([thai_reverse_vocab[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "output_encode = lambda s: [english_vocab[c] for c in s] # encoder: take a string, output a list of integers\n",
        "output_decode = lambda l: ''.join([english_reverse_vocab[i] for i in l]) # decoder: take a list of integers, output a string"
      ],
      "metadata": {
        "id": "Er5aFTBrvzy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "for line in name_th:\n",
        "    line = [l for l in line] #change from string to list\n",
        "    X.append(torch.tensor(input_encode(line)))\n",
        "Y = []\n",
        "for line in name_en:\n",
        "    line = [l for l in line] #change from string to list\n",
        "    Y.append(torch.tensor(output_encode(line)))\n",
        "\n",
        "X = nn.utils.rnn.pad_sequence(X, batch_first = True)\n",
        "Y = nn.utils.rnn.pad_sequence(Y, batch_first = True)"
      ],
      "metadata": {
        "id": "pzItgRSmvrmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Encoded Thai names: {X}\")\n",
        "print(f\"Encoded English names: {Y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGgxlHqsudMw",
        "outputId": "1d3f7d62-7ae1-404e-b05a-ab20f7cce770"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded Thai names: tensor([[21, 15, 65,  ...,  0,  0,  0],\n",
            "        [22,  2, 63,  ...,  0,  0,  0],\n",
            "        [20, 47, 65,  ...,  0,  0,  0],\n",
            "        ...,\n",
            "        [15, 43, 49,  ...,  0,  0,  0],\n",
            "        [ 8, 62,  2,  ...,  0,  0,  0],\n",
            "        [22,  2, 54,  ...,  0,  0,  0]])\n",
            "Encoded English names: tensor([[11, 13, 15,  ...,  0,  0,  0],\n",
            "        [16, 18, 15,  ...,  0,  0,  0],\n",
            "        [20, 18,  4,  ...,  0,  0,  0],\n",
            "        ...,\n",
            "        [11, 15, 21,  ...,  0,  0,  0],\n",
            "        [16, 18, 15,  ...,  0,  0,  0],\n",
            "        [16, 18, 15,  ...,  0,  0,  0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2o6Zcju_H59z",
        "outputId": "831674a7-c657-485e-ee2b-12727b635699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10887, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVQ6hXv_H9ha",
        "outputId": "e43f6f0f-e055-47cc-b849-5fcef2e55180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10887, 19])"
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "W3aXyJBEC-j_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NameDataset(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "      self.encoded = X.long()\n",
        "      self.label = y.long()\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      return {\"x\" :self.encoded[idx], \"y\":self.label[idx]}\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.encoded)"
      ],
      "metadata": {
        "id": "-yirzlseC9NS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NameDataModule(L.LightningDataModule):\n",
        "\n",
        "  def __init__(self, train_data, y, batch_size, num_workers=0):\n",
        "      super().__init__()\n",
        "      self.train_data = train_data\n",
        "      self.y = y\n",
        "      self.batch_size = batch_size\n",
        "      self.num_workers = num_workers\n",
        "\n",
        "\n",
        "  def setup(self, stage: str):\n",
        "      pass\n",
        "\n",
        "  def collate_fn(self, batch):\n",
        "      one_hot_x = torch.stack([F.one_hot(b[\"x\"], num_classes=len(thai_vocab)) for b in batch])\n",
        "      return {\"x\": one_hot_x.float(), \"y\": torch.stack([b[\"y\"] for b in batch])}\n",
        "\n",
        "  def train_dataloader(self):\n",
        "      train_dataset = NameDataset(self.train_data, self.y)\n",
        "      return DataLoader(\n",
        "              train_dataset,\n",
        "              batch_size=self.batch_size,\n",
        "              num_workers=self.num_workers,\n",
        "              shuffle=True,\n",
        "              collate_fn=self.collate_fn\n",
        "        )\n"
      ],
      "metadata": {
        "id": "qUPAB7LTDFOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFSG1FqK1ZSy"
      },
      "source": [
        "# Attention Mechanism\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO 2: Code your own (key-value) attention mechnism\n",
        "* PLEASE READ: you DO NOT have to follow all the details in (Daniluk, et al. 2017). You just need to create a key-value attention mechanism where the \"key\" part of the mechanism is used for attention score calculation, and the \"value\" part of the mechanism is used to encode information to create a context vector.  \n",
        "* fill code for one_step_attention function\n",
        "\n"
      ],
      "metadata": {
        "id": "HAlOrhbismQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_step_attention(h, s_prev, linear_1, linear_2):\n",
        "\n",
        "    #Split into Key-Value\n",
        "    key, value = torch.split(h, h.shape[-1] // 2, dim=-1)\n",
        "    #do concat with s_prev.\n",
        "    #hint: you will need to use s_prev.repeat(...) somehow so that it has the same dimension as the key\n",
        "    #hint2: s_prev.unsqueeze() could also be useful\n",
        "\n",
        "\n",
        "    #Attention function###\n",
        "    # use layer(s) from your model to calculate attention_scores and then softmax\n",
        "    # calculate a context vector\n",
        "    s_prev = s_prev.unsqueeze(1).repeat(1, key.shape[1], 1)\n",
        "    concat = torch.cat([key, s_prev], dim=-1)\n",
        "    e = F.tanh(linear_1(concat))\n",
        "    energies = linear_2(e)\n",
        "    attention_scores = F.softmax(energies, dim=1)\n",
        "    temp = attention_scores * value\n",
        "    context = torch.sum(temp, dim=1)\n",
        "\n",
        "    return context, attention_scores"
      ],
      "metadata": {
        "id": "avnlc6p9BZDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translation Model"
      ],
      "metadata": {
        "id": "6zWN02ZtuOIU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0phyUQYg1ZS8"
      },
      "source": [
        "## TODO3: Create and train your encoder/decoder model here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji_rUPhK1ZS9"
      },
      "source": [
        "class AttentionModel(L.LightningModule):\n",
        "    def __init__(self):\n",
        "\n",
        "        super().__init__()\n",
        "        self.n_h = 32   #hidden dimensions for encoder\n",
        "        self.n_s = 64  #hidden dimensions for decoder\n",
        "        self.learning_rate = learning_rate\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        #encoder can be any RNN of your choice\n",
        "        # Encoder: Bidirectional LSTM\n",
        "        self.lstm = nn.LSTM(input_vocab_size, self.n_h, bidirectional=True, batch_first=True)\n",
        "        self.num_directions = 2  # Bidirectional LSTM\n",
        "\n",
        "        #decoder has to be (any) RNNCell since we will need to calculate attention for each timestep manually\n",
        "        # Decoder: LSTMCell\n",
        "        self.decoder_lstm_cell = nn.LSTMCell(self.n_s // 2, self.n_s)\n",
        "        self.output_layer = nn.Linear(self.n_s, len(english_vocab))\n",
        "\n",
        "        # Output layer\n",
        "        self.output_layer = nn.Linear(self.n_s, output_vocab_size)\n",
        "\n",
        "        #attention\n",
        "        # Attention mechanism layers\n",
        "        self.fc1 = nn.Linear(self.n_h*2*3//2, self.n_h)\n",
        "        self.fc2 = nn.Linear(self.n_h, 1)\n",
        "\n",
        "\n",
        "    def forward(self, src, return_attention=False): #use return_attention only when you want to get the attention scores for visualizing\n",
        "        #pass the input to the encoder\n",
        "        lstm_out, _ = self.lstm(src)\n",
        "\n",
        "        #Initialize the LSTM states. We have to do this since we are using LSTMCell (https://pytorch.org/docs/stable/generated/torch.nn.LSTMCell.html)\n",
        "        #These states will get updated while we are decoding\n",
        "        decoder_s = torch.randn(src.shape[0], self.n_s).to(self.decoder_lstm_cell.weight_ih.device)\n",
        "        decoder_c = torch.randn(src.shape[0], self.n_s).to(self.decoder_lstm_cell.weight_ih.device)\n",
        "\n",
        "        #Iterate until max_output_length (Decoding)\n",
        "        prediction = torch.zeros((src.shape[0], maxlen_out, len(english_vocab))).to(self.decoder_lstm_cell.weight_ih.device)\n",
        "        attention_scores = [] #to store the score for each step\n",
        "        for t in range(maxlen_out):\n",
        "\n",
        "            #Perform one step of the attention mechanism to calculate the context vector at timestep t\n",
        "            context, attention_score = one_step_attention(lstm_out, decoder_s, self.fc1, self.fc2)\n",
        "\n",
        "            # Feed the context vector to the decoder.\n",
        "            decoder_s, decoder_c = self.decoder_lstm_cell(context, (decoder_s, decoder_c))\n",
        "\n",
        "            # Pass the decoder hidden output to the output layer (softmax)\n",
        "            out = self.output_layer(decoder_s)\n",
        "\n",
        "            # Put the predicted output into the list for this timestep\n",
        "            prediction[:, t] = out\n",
        "\n",
        "            attention_scores.append(attention_score)\n",
        "\n",
        "        return (prediction, attention_scores if return_attention else None)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src = batch['x']\n",
        "        target = batch['y']\n",
        "        max_output_length = target.shape[1]\n",
        "\n",
        "        # Forward pass\n",
        "        predictions, _ = self(src, max_output_length)\n",
        "        predictions = predictions.reshape(-1, self.output_layer.out_features)\n",
        "        target = target.reshape(-1)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = self.criterion(predictions, target)\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
        "        # Extract the input data from the batch\n",
        "        src = batch['x']\n",
        "\n",
        "        with torch.no_grad():  # Disable gradient computation for inference\n",
        "            # Get the predictions and attention scores from the model\n",
        "            prediction, attention_scores = self(src, return_attention=True)\n",
        "\n",
        "            # Apply softmax to the predictions to get probabilities\n",
        "            prediction = F.softmax(prediction, dim=-1)\n",
        "\n",
        "            # Get the index of the highest probability for each prediction\n",
        "            prediction = torch.argmax(prediction, dim=-1)\n",
        "\n",
        "            # Print the decoded predictions as strings\n",
        "            for pred in prediction:\n",
        "                print(\"\".join(output_decode(pred.cpu().numpy())))\n",
        "\n",
        "            return prediction, attention_scores\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return optim.Adam(self.parameters(), lr=self.learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example setup\n",
        "input_vocab_size = len(thai_vocab)  # Size of the input vocabulary\n",
        "output_vocab_size = len(english_vocab)  # Size of the output vocabulary\n",
        "learning_rate = 1e-3\n",
        "\n",
        "# Initialize the model\n",
        "model = AttentionModel()"
      ],
      "metadata": {
        "id": "pSM9dgDcCz1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_module = NameDataModule(X, Y, batch_size=32, num_workers=2)"
      ],
      "metadata": {
        "id": "RqrvmJalDLzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lightning import Trainer\n",
        "from lightning.pytorch.loggers import WandbLogger\n",
        "wandb_logger = WandbLogger(project=\"hw3.1_attention\")"
      ],
      "metadata": {
        "id": "_sFjzKX8SECo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGWSzS-X1ZTO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d92eeb9-a18f-42ad-c4a0-a75d13c89488"
      },
      "source": [
        "trainer = L.Trainer(\n",
        "    max_epochs=100,\n",
        "    logger=wandb_logger\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZMi782c1ZTQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711,
          "referenced_widgets": [
            "9b2d779ecd4e49339e397af4e366e302",
            "f8b78bdad2af43479507336383f5b1fc",
            "919d38c9694e4e5dba41ffdfefe2f5c5",
            "df2ee00b533046f08a2db2051eaa6159",
            "0f95b4a99eca48c0a2693f8a3b6186b6",
            "555043b0f2e84381a34f4dff0f5c379e",
            "c58683ab7d124f3ebaf5cb38046c666e",
            "a3002562040044b986f5c9608fcd0c9b",
            "f6feb614ebc2427fb6bb815153f49ea8",
            "387f274446264bcf8fc4b64c6b003d49",
            "e533664c11bb43b7b413e1f303bcb3ef"
          ]
        },
        "outputId": "76842543-b4de-471a-8ff7-b32153376548"
      },
      "source": [
        "trainer.fit(model, data_module)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name              | Type             | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | criterion         | CrossEntropyLoss | 0      | train\n",
            "1 | lstm              | LSTM             | 25.6 K | train\n",
            "2 | decoder_lstm_cell | LSTMCell         | 25.1 K | train\n",
            "3 | output_layer      | Linear           | 1.6 K  | train\n",
            "4 | fc1               | Linear           | 3.1 K  | train\n",
            "5 | fc2               | Linear           | 33     | train\n",
            "---------------------------------------------------------------\n",
            "55.4 K    Trainable params\n",
            "0         Non-trainable params\n",
            "55.4 K    Total params\n",
            "0.222     Total estimated model params size (MB)\n",
            "6         Modules in train mode\n",
            "0         Modules in eval mode\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name              | Type             | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | criterion         | CrossEntropyLoss | 0      | train\n",
            "1 | lstm              | LSTM             | 25.6 K | train\n",
            "2 | decoder_lstm_cell | LSTMCell         | 25.1 K | train\n",
            "3 | output_layer      | Linear           | 1.6 K  | train\n",
            "4 | fc1               | Linear           | 3.1 K  | train\n",
            "5 | fc2               | Linear           | 33     | train\n",
            "---------------------------------------------------------------\n",
            "55.4 K    Trainable params\n",
            "0         Non-trainable params\n",
            "55.4 K    Total params\n",
            "0.222     Total estimated model params size (MB)\n",
            "6         Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b2d779ecd4e49339e397af4e366e302"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: `Trainer.fit` stopped: `max_epochs=100` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=100` reached.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5BLw1Ir1ZTT"
      },
      "source": [
        "# Test Your Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO4: Test your model on 5 examples of your choice including your name!\n",
        "\n",
        "Example Output:\n",
        "```\n",
        "prayutthatha</s></s>aa</s></s>a</s>\n",
        "somchai</s></s></s></s>a</s></s>a</s></s></s></s></s>\n",
        "thanathon</s></s></s></s></s></s></s></s></s></s></s>\n",
        "newin</s>i</s></s></s></s></s></s></s></s></s></s></s></s></s>\n",
        "suthep</s>he</s></s></s></s></s></s></s></s></s></s></s>\n",
        "prawit</s></s></s></s></s></s></s></s></s></s></s></s></s></s>\n",
        "chatchachatti</s></s>i</s></s></s></s>\n",
        "```\n",
        "\n",
        "<font color='blue'>Paste your model predictions in MyCourseVille</font>"
      ],
      "metadata": {
        "id": "VRLjZzBMtCdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EXAMPLES = ['ประยุทธ','สมชาย','ธนาธร','เนวิน','สุเทพ','ประวิตร์','ชัชชาติ', 'กิตติพัฒน์']"
      ],
      "metadata": {
        "id": "6stNACsUP9h-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AttentionModel.load_from_checkpoint(\"/content/hw3.1_attention/6wyxe0lf/checkpoints/epoch=99-step=34100.ckpt\")\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "kbolC8XIhR3t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50ef2cb3-fbc1-4fd8-8612-309cab7325ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AttentionModel(\n",
              "  (criterion): CrossEntropyLoss()\n",
              "  (lstm): LSTM(66, 32, batch_first=True, bidirectional=True)\n",
              "  (decoder_lstm_cell): LSTMCell(32, 64)\n",
              "  (output_layer): Linear(in_features=64, out_features=24, bias=True)\n",
              "  (fc1): Linear(in_features=96, out_features=32, bias=True)\n",
              "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the input data\n",
        "predict_data = []\n",
        "for name in EXAMPLES:\n",
        "    name_list = [char for char in name]  # Convert string to a list of characters\n",
        "    predict_data.append(torch.tensor(input_encode(name_list)))  # Encode the name and append to the list\n",
        "\n",
        "# Define a custom collate function for batching\n",
        "def collate_fn(batch):\n",
        "    # Perform one-hot encoding on each batch item and stack them together\n",
        "    one_hot_x = torch.stack([F.one_hot(item[\"x\"], num_classes=len(thai_vocab)) for item in batch])\n",
        "    return {\"x\": one_hot_x.float()}  # Return the one-hot encoded data as a float tensor\n",
        "\n",
        "# Pad the sequence to ensure consistent length for batching\n",
        "predict_data = nn.utils.rnn.pad_sequence(predict_data, batch_first=True)\n",
        "\n",
        "# Create a dataset for predictions with placeholder labels (0 for each item)\n",
        "predict_dataset = NameDataset(predict_data, torch.tensor([0] * len(predict_data)))\n",
        "\n",
        "# Load the data into a DataLoader, using the custom collate function\n",
        "predict_loader = DataLoader(predict_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn, num_workers=0)\n"
      ],
      "metadata": {
        "id": "tQuKUFVvPrSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = trainer.predict(model, predict_loader)"
      ],
      "metadata": {
        "id": "LsN71S9uQ9wo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223,
          "referenced_widgets": [
            "d99f005e0db64121bd272347b193ecf2",
            "52c7190f07414fe580c691ccc3231f13",
            "82116e868c724debb84e0de00383482a",
            "05ac5405cc7f41e0a80fcae062ff7b4c",
            "cadeb7b11c38405c99b1cb9e4cfa3a93",
            "9c3e1443c1f246f993f9acbc15ac471b",
            "fd083703da314098a130d6562dbdfaff",
            "4db1533616214c148597a944c22d6a68",
            "01aac22f0e934d4a9be960f0dfcb63cf",
            "8b6109a3ed5b416cb431a4d41cf590b0",
            "e28a14ab1d254150951ab0a047a949b3"
          ]
        },
        "outputId": "c012edfe-81fc-4e23-d673-3bbea732c13e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predicting: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d99f005e0db64121bd272347b193ecf2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prayuttta<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "samchaii<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "thanathan<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "nawen<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "suthee<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "prawat<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "chaacchtt<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "kittiphaa<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o3893RL1ZT8"
      },
      "source": [
        "## TODO 5: Show your visualization of attention scores on one of your example\n",
        "\n",
        "<font color='blue'>Paste your visualization image in MyCourseVille</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHysSqYJ1ZUA"
      },
      "source": [
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdktVnMv1ZTh"
      },
      "source": [
        "prediction, attention_scores = zip(*output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode the prediction (without trailing zeros)\n",
        "output_text = \"\".join(output_decode(c) for c in prediction[0][:np.argmax(prediction[0] == 0)].cpu().numpy())\n",
        "output_text = list(output_text.replace('<pad>', \"\"))\n",
        "output_text.append('<eow>')\n",
        "\n",
        "# Prepare xlabels\n",
        "xlabels = [c for c in EXAMPLES[0]]  # Use the original EXAMPLES string\n",
        "xlabels.append('<pad>')  # Add <PAD> for the padding token\n",
        "\n",
        "# Adjust the attention matrix to match the length of output_text\n",
        "attn_viz = torch.stack(attention_scores[0]).squeeze().cpu().numpy()\n",
        "attn_viz = attn_viz.transpose(1,0)\n",
        "\n",
        "# Adjust the attention matrix and xlabels to match\n",
        "attn_viz = attn_viz[:, :len(output_text)]\n",
        "attn_viz = attn_viz.T  # Transpose it to match the visualization format\n",
        "\n",
        "# Ensure xlabels matches the number of columns in the attention matrix\n",
        "while len(xlabels) < attn_viz.shape[1]:\n",
        "    xlabels.append('<pad>')  # Extend xlabels with <PAD> until it matches\n",
        "\n",
        "# Create the heatmap\n",
        "ax = sns.heatmap(attn_viz, linewidth=0.5)\n",
        "ax.set_yticklabels(output_text, rotation=30)\n",
        "ax.set_xticklabels(xlabels, rotation=60)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "c8Y51cBBcEHC",
        "outputId": "943c34bf-37f9-47f8-e1f4-e20948a0550c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}